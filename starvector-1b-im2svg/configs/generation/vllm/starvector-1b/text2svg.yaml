# General configuration
run:
  out_dir: "eval_results"
  api:
    key: "EMPTY"
    base_url: "http://0.0.0.0:40000/v1"

# Model configuration
model:
  name: "starvector/starvector-1b-text2svg"
  generation_engine: "vllm"
  task: text2svg
  torch_dtype: bfloat16
  image_processor: null

# Dataset configuration
dataset:
  name: svg-stack
  batch_size: 2
  num_workers: 4
  num_samples: -1

# vllm https://docs.vllm.ai/en/v0.5.5/dev/sampling_params.html
# hf https://huggingface.co/docs/transformers/main_classes/text_generation
generation_params:
  # Text generation parameters
  max_length: 16384
  min_length: 10
  num_beams: 1
  temperature: 0.6
  generation_sweep: false # Controls multi-temperature sampling, rank based sampling
    # num_generations_different_temp: 1
    # min_temperature: 0.0
    # max_temperature: 0.5
  num_captions: 1
  frequency_penalty: 0.0
  presence_penalty: 0.0
  top_p: 0.9
  logit_bias: False # if this is not false, the model will be biased to the svg_end_token_id
  stream: false