# General configuration
run:
  project_name: "starvector-RL-eval"
  out_dir: "eval_results"
  device: cuda
  report_to: wandb
  run_id: test-run
  log_images: false

# Model configuration
model:
  name: "starvector/starvector-1b-text2svg"
  generation_engine: "hf"
  task: text2svg
  torch_dtype: bfloat16
  image_processor: null

# Dataset configuration
dataset:
  name: svg-stack
  batch_size: 2
  num_workers: 4
  num_samples: -1

# vllm https://docs.vllm.ai/en/v0.5.5/dev/sampling_params.html
# hf https://huggingface.co/docs/transformers/main_classes/text_generation
generation_params:
  max_length: 10000
  min_length: 10
  num_beams: 3
  temperature: 1.0
  num_captions: 1
  repetition_penalty: 1.0
  length_penalty: 0.5
  presence_penalty: 0.0 # only used in vllm 
  frequency_penalty: 0.0
  top_p: 0.95
  do_sample: true # turn this off for greedy decoding
  use_nucleus_sampling: true
  im_size: 384
  dpi: 2
  scale: 300
  logit_bias: 10 # if this is not false, the model will be biased to the svg_end_token_id
  stream: false